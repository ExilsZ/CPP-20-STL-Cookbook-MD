# 第 9 章并发和并行

并发性和并行性指的是在不同的执行线程中运行代码的能力。并发性是在后台运行线程的能力，并行性是在处理器的不同内核中同时运行线程的能力。

运行时库以及主机操作系统，将为给定硬件环境中的线程，在并发和并行执行模型之间进行选择。

在现代多任务操作系统中，`main()` 函数已经代表了一个执行线程。当一个新线程启动时，可由现有的线程派生。

C++标准库中，std::thread 类提供了线程执行的基本单元。其他类构建在线程之上，以提供锁、互斥和其他并发模式。根据系统架构的不同，执行线程可以在一个处理器上并发运行，也可以在不同的内核上并行运行。

- 休眠一定的时间
- std::thread------实现并发
- std::async------实现并发
- STL 算法与执行策略
- 互斥锁和锁------安全地共享数据
- std::atomic------共享标志和值
- std::call_once------初始化线程
- std::condition_variable------解决生产者 - 消费者问题
- 实现多个生产者和消费者

## 9.1.相关准备

本章所有的例子和源代码都可以在本书的 GitHub 库中找到，网址是[chap09](https://github.com/PacktPublishing/CPP-20-STL-Cookbook/tree/main/chap09)。

## 9.2.休眠一定的时间

`<thread>` 头文件提供了两个使线程进入休眠状态的函数，sleep_for() 和 sleep_until()。这两个函数都在 std::this_thread 命名空间中。

本节探讨了这些函数的使用，我们将在本章后面使用它们。

### How to do it

看看如何使用 sleep_for() 和 sleep_until() 函数：

- 与休眠相关的函数在 std::this_thread 命名空间中。只有几个符号，可以为 std::this_thread 和 std::chrono_literals 使用 using 指令：

    ```cpp
    using namespace std::this_thread;
    using namespace std::chrono_literals;
    ```

    chrono_literals 命名空间具有表示持续时间的符号，例如 1s 表示一秒，100ms 表示 100 毫秒。

- 在 main() 中，用 steady_clock::now() 标记一个时间点，这样就可以计算测试时间了：

    ```cpp
    int main() {
        auto t1 = steady_clock::now();
        cout << "sleep for 1.3 seconds\n";
        sleep_for(1s + 300ms);
        cout << "sleep for 2 seconds\n";
        sleep_until(steady_clock::now() + 2s);
        duration<double> dur1 = steady_clock::now() - t1;
        cout << format("total duration: {:.5}s\n",
            dur1.count());
    }
    ```

    sleep_for() 函数的作用是：接受一个 duration 对象来指定睡眠时间。参数 (1s +
    300ms) 使用 chrono_literal 操作符返回一个表示 1.3 秒的 duration 对象。

    sleep_until() 函数接受一个 time_point 对象来指定从睡眠状态恢复的特定时间。使用 chrono_literal 操作符，来修改从 steady_clock::now() 返回的 time_point 对象。

    输出：

    ```shell
    sleep for 1.3 seconds sleep for 2 seconds total
    duration: 3.3005s
    ```

### How it works

sleep_for(duration) 和 sleep_until(time_point) 函数在指定的时间内暂停当前线程的执行，或者直到到达 time_point。若支持的话，sleep_for() 函数将使用 steady_clock 实现。

否则，持续时间可能会有所调整。由于调度或资源延迟，这两个功能可能会阻塞更长的时间。

### There's more

一些系统支持 POSIX 函数 sleep()，会在指定的秒数内暂停执行：

```cpp
unsigned int sleep(unsigned int seconds);
```

sleep() 函数是 POSIX 标准的一部分，而不是 C++标准的一部分。

## 9.3.std::thread------实现并发

线程是并发的单位，`main()` 函数可以看作是执行的主线程。在操作系统上下文中，主线程与其他进程拥有的其他线程并发运行。

thread 类是 STL 中并发性的根本，所有其他并发特性都建立在线程类的基础上。

本节中，我们将了解 std::thread 的基础知识，以及 join() 和 detach() 如何确定其执行上下文。

### How to do it

在这个示例中，我们创建了一些 std::thread 对象，并测试了它们的执行选项。

- 从线程休眠函数开始，单位是毫秒：

    ```cpp
    void sleepms(const unsigned ms) {
        using std::chrono::milliseconds;
        std::this_thread::sleep_for(milliseconds(ms));
    }
    ```

    sleep_for() 函数接受一个 duration 对象，并在指定的时间内阻塞当前线程的执行。sleepms() 函数作为一个方便的包装器，其接受一个 unsigned 值，表示休眠的毫秒数。

- 现在，需要线程的一个函数。这个函数休眠的毫秒数是可变的，基于一个整数参数：

    ```cpp
    void fthread(const int n) {
        cout << format("This is t{}\n", n);
        for(size_t i{}; i < 5; ++i) {
            sleepms(100 * n);
            cout << format("t{}: {}\n", n, i + 1);
        }
        cout << format("Finishing t{}\n", n);
    }
    ```

    fthread() 调用 sleepms() 5 次，每次休眠 100 * n 毫秒。

- 可以在一个单独的线程中 (比如主线程) 运行 std::thread:

    ```cpp
    int main() {
        thread t1(fthread, 1);
        cout << "end of main()\n";
    }
    ```

    可以编译，但运行时会有错误：

    ```shell
    terminate called without an active exception Aborted
    ```

    (错误信息会有所不同。这是在 Debian 和 GCC 上的错误信息。)

    问题在于，当线程对象超出作用域时，操作系统不知道该如何处理。必须指定调用者是否等待线程，或者是否分离并独立运行。

- 使用 join() 来指示调用者将等待线程完成：

    ```cpp
    int main() {
        thread t1(fthread, 1);
        t1.join();
        cout << "end of main()\n";
    }
    ```

    输出为：

    ```text
    This is t1 t1: 1 t1: 2 t1: 3 t1: 4 t1: 5 Finishing t1
    end of main()
    ```

    现在，main() 会等待线程完成。

- 若使用 detach()，那么 main() 不会等待，程序在线程运行之前就结束了：

    ```cpp
    thread t1(fthread, 1);
    t1.detach();
    ```

    输出为：

    ```text
    end of main()
    ```

- 当线程分离后，需要给它一些运行的时间：

    ```cpp
    thread t1(fthread, 1);
    t1.detach();
    cout << "main() sleep 2 sec\n";
    sleepms(2000);
    ```

    输出为：

    ```text
    main() sleep 2 sec This is t1 t1: 1 t1: 2 t1: 3 t1: 4
    t1: 5 Finishing t1 end of main()
    ```

- 分离第二个线程，看看会发生什么：

    ```cpp
    int main() {
        thread t1(fthread, 1);
        thread t2(fthread, 2);
        t1.detach();
        t2.detach();
        cout << "main() sleep 2 sec\n";
        sleepms(2000);
        cout << "end of main()\n";
    }
    ```

    输出为：

    ```text
    main() sleep 2 sec This is t1 This is t2 t1: 1 t2: 1
    t1: 2 t1: 3 t2: 2 t1: 4 t1: 5 Finishing t1 t2: 3 t2: 4 t2: 5
    Finishing t2 end of main()
    ```

    因为 fthread() 函数使用它的形参作为 sleepms() 的乘法器，所以第二个线程比第一个线程运行得慢一些。我们可以看到计时器在输出中交错。

- 若使用 join()，而不是 detatch() 来执行此操作，会得到类似的结果：

    ```cpp
    int main() {
        thread t1(fthread, 1);
        thread t2(fthread, 2);
        t1.join();
        t2.join();
        cout << "end of main()\n";
    }
    ```

    输出为：

    ```text
    This is t1 This is t2 t1: 1 t2: 1 t1: 2 t1: 3 t2: 2
    t1: 4 t1: 5 Finishing t1 t2: 3 t2: 4 t2: 5 Finishing t2 end of
    main()
    ```

    因为 join() 等待线程完成，所以不再需要 main() 中 2 秒的 sleepms() 来等待线程完成。

### How it works

std::thread 对象表示一个执行线程，对象和线程之间是一对一的关系。一个线程对象表示一个线程，一个线程由一个线程对象表示。线程对象不能复制或赋值，但可以移动。

其构造函数是这样：

```cpp
explicit thread( Function&& f, Args&&… args );
```

线程是用一个函数指针和零个或多个参数构造的。函数会立即调用：

```cpp
thread t1(fthread, 1);
```

这将创建对象 t1，并立即以字面值 1 作为参数调用函数 fthread(int)。

创建线程后，必须在线程上使用 join() 或 detach():

```cpp
t1.join();
```

join() 方法阻塞调用线程的执行，直到 t1 线程完成：

```cpp
t1.detach();
```

detach() 方法允许调用线程独立于 t1 线程继续运行。

### There's more

C++20 提供了 std::jthread，其会自动在作用域的末尾汇入创建线程：

```cpp
int main() {
    std::jthread t1(fthread, 1);
    cout "< "end of main("\n";
}
```

输出为：

```text
end of main() This is t1 t1: 1 t1: 2 t1: 3 t1: 4 t1: 5
Finishing t1
```

t1 线程可以独立执行，在其作用域的末尾会自动汇入 main() 线程。

## 9.4.std::async------实现并发

std::async() 异步运行一个目标函数，并返回一个携带目标函数返回值的 std::future 对象。通过这种方式，async() 的操作很像 std::thread，但允许函数有返回值。

通过几个例子来了解一下 std::async() 的使用。

### How to do it

在其最简单的形式中，std::async() 函数执行与 std::thread 相同的任务，不需要调用 join() 或 detach()，同时还允许通过 std::future 对象返回值。

这个示例中，将使用一个函数来计算一个范围内质数的数量。可以使用 chrono::steady_clock 为每个线程的进行计时。

- 先从别名开始：

    ```cpp
    using launch = std::launch;
    using secs = std::chrono::duration<double>;
    ```

    std::launch 有启动策略常量，用于 async() 调用。secs 别名是一个持续时间类，用于为质数计算计时。

- 我们的目标函数计算范围内的质数。这本质上是一种通过占用一些时钟周期，来理解执行策略的方法：

    ```cpp
    struct prime_time {
        secs dur{};
        uint64_t count{};
    };
    prime_time count_primes(const uint64_t& max) {
        prime_time ret{};
        constexpr auto isprime = [](const uint64_t& n) {
            for(uint64_t i{ 2 }; i < n / 2; ++i) {
                if(n % i == 0) return false;
            }
            return true;
        };
        uint64_t start{ 2 };
        uint64_t end{ max };
        auto t1 = steady_clock::now();
        for(uint64_t i{ start }; i <= end ; ++i) {
            if(isprime(i)) ++ret.count;
        }
        ret.dur = steady_clock::now() - t1;
        return ret;
    }
    ```

    prime_time 结构用于返回值，可用于 duration 和 count，这样就可以计算循环本身的时间。若一个值是质数，isprime 返回 true。我们使用 steady_clock，来计算质数计数循环的持续时间。

- 在 main() 中，调用函数并报告其运行时间：

    ```cpp
    int main() {
        constexpr uint64_t MAX_PRIME{ 0x1FFFF };
        auto pt = count_primes(MAX_PRIME);
        cout << format("primes: {} {:.3}\n", pt.count,
            pt.dur);
    }
    ```

    输出为：

    ```text
    primes: 12252 1.88008s
    ```

- 现在，可以用 std::async() 异步运行 count_primes():

    ```cpp
    int main() {
        constexpr uint64_t MAX_PRIME{ 0x1FFFF };
        auto primes1 = async(count_primes, MAX_PRIME);
        auto pt = primes1.get();
        cout << format("primes: {} {:.3}\n", pt.count,
            pt.dur);
    }
    ```

    这里，使用 count_primes 函数和 MAX_PRIME 参数调用 async()，这 count_primes 函数放在后台运行。

    async() 返回 std::future 对象，该对象携带异步操作的返回值。future 对象的 get() 是阻塞式的，会等到异步函数完成，获取该函数的返回对象。

    这与没有 async() 时运行的时间几乎相同：

    ```shell
    primes: 12252 1.97245s
    ```

- async() 函数可选地将执行策略标志作为其第一个参数：

    ```shell
    auto primes1 = async(launch::async, count_primes, MAX_ PRIME);
    ```

    选择是异步或延迟的，这些标志位于 std::launch 命名空间中。

    async 标志启用异步操作，deferred 标志启用延迟计算。这些标志是位映设的，可以与按位或 | 操作符组合使用。

    默认情况下，这两个位都要设置，就和 async|deferred 一样。

- 可以使用 async() 同时运行函数的几个实例：

    ```cpp
    int main() {
        constexpr uint64_t MAX_PRIME{ 0x1FFFF };
        list<std::future<prime_time>> swarm;
        cout << "start parallel primes\n";
        auto t1{ steady_clock::now() };
        for(size_t i{}; i < 15; ++i) {
            swarm.emplace_back(
            async(launch::async, count_primes,
            MAX_PRIME)
            );
        }
        for(auto& f : swarm) {
            static size_t i{};
            auto pt = f.get();
            cout << format("primes({:02}): {} {:.5}\n",
            ++i, pt.count, pt.dur);
        }
        secs dur_total{ steady_clock::now() - t1 };
        cout << format("total duration: {:.5}s\n",
            dur_total.count());
    }
    ```

    我们知道 async 返回一个 future 对象。因此，可以通过将未来对象存储在容器中来运行 15 个线程。以下是我运行在 Windows 设备 (6 核 i7) 上的输出：

    ```shell
    start parallel primes primes(01): 12252 4.1696s
    primes(02): 12252 3.7754s primes(03): 12252 3.78089s primes(04):
    12252 3.72149s primes(05): 12252 3.72006s primes(06): 12252 4.1306s
    primes(07): 12252 4.26015s primes(08): 12252 3.77283s primes(09):
    12252 3.77176s primes(10): 12252 3.72038s primes(11): 12252 3.72416s
    primes(12): 12252 4.18738s primes(13): 12252 4.07128s primes(14):
    12252 2.1967s primes(15): 12252 2.22414s total duration: 5.9461s
    ```

    尽管，6 核 i7 不能在不同的核中运行所有进程，但仍然可以在 6 秒内完成 15 个实例。

    看起来它在 4 秒内完成了前 13 个线程，然后再花 2 秒完成最后 2 个线程。这似乎利用了 Intel 的超线程技术，该技术允许在某些情况下在一个核心中运行 2 个线程。

    当在 12 核 Xeon 上运行相同的代码时，会得到这样的结果：

    ```shell
    start parallel primes primes(01): 12252 0.96221s
    primes(02): 12252 0.97346s primes(03): 12252 0.92189s primes(04):
    12252 0.97499s primes(05): 12252 0.98135s primes(06): 12252 0.93426s
    primes(07): 12252 0.90294s primes(08): 12252 0.96307s primes(09):
    12252 0.95015s primes(10): 12252 0.94255s primes(11): 12252 0.94971s
    primes(12): 12252 0.95639s primes(13): 12252 0.95938s primes(14):
    12252 0.92115s primes(15): 12252 0.94122s total duration: 0.98166s
    ```

    12 核的至强处理器可以在一秒钟内完成全部 15 个进程的任务。

### How it works

理解 std::async 的关键在于其对 std::promise 和 std::future 的使用。

promise 类允许线程存储一个对象，以后可以由 future 对象进行异步检索。

例如，有这样一个函数：

```cpp
void f() {
    cout << "this is f()\n";
}
```

可以用 std::thread 运行：

```cpp
int main() {
    std::thread t1(f);
    t1.join();
    cout << "end of main()\n";
}
```

这对于没有返回值的简单函数来说很好。当想从 f() 返回一个值时，可以使用 promise 和 future。

在 main() 线程中设置了 promise 和 future 对象：

```cpp
int main() {
    std::promise<int> value_promise;
    std::future<int> value_future =
        value_promise.get_future();
    std::thread t1(f, std::move(value_promise));
    t1.detach();
    cout << format("value is {}\n", value_future.get());
    cout << "end of main()\n";
}
```

然后，将 promise 对象传递给函数：

```cpp
void f(std::promise<int> value) {
    cout << "this is f()\n";
    value.set_value(47);
}
```

promise 对象不能复制，因此需要使用 std::move 将其传递给函数。

promise 对象充当到 future 对象的桥梁，其允许在值可用的前提下，对其进行检索。

std::async() 只是一个辅助函数，用于简化 promise 和 future 对象的创建。可以这样使用 async():

```cpp
int f() {
    cout << "this is f()\n";
    return 47;
}

int main() {
    auto value_future = std::async(f);
    cout << format("value is {}\n", value_future.get());
    cout << "end of main()\n";
}
```

这就是 async() 的值。在很多情况下，promise 与 future 的组合使用起来更容易。

## 9.5.STL 算法与执行策略

从 C++17 开始，许多标准的 STL 算法可以并行执行。该特性允许算法将其工作拆分为子任务，以便在多个核上同时运行。这些算法接受一个执行策略对象，该对象指定应用于算法的并行度类型，该特性需要硬件支持。

### How to do it

执行策略在 `<execution>` 头文件中和 std::
Execution 命名空间中定义。本节中，我们将使用 std::transform() 算法测试可用的策略：

- 出于计时的目的，将使用带有 std::milli 比率的 duration 对象，这样就可以以毫秒为单位进行测量：

    ```cpp
    using dur_t = duration<double, std::milli>;
    ```

- 出于演示目的，将从一个具有 1000 万个随机值的 `vector<unsigned>` 开始：

    ```cpp
    int main() {
        std::vector<unsigned> v(10 * 1000 * 1000);
        std::random_device rng;
        for(auto &i : v) i = rng() % 0xFFFF;
        ...
    }
    ```

- 现在，进行一个简单的变换：

    ```cpp
    auto mul2 = [](int n){ return n * 2; };
    auto t1 = steady_clock::now();
    std::transform(v.begin(), v.end(), v.begin(), mul2);
    dur_t dur1 = steady_clock::now() - t1;
    cout << format("no policy: {:.3}ms\n", dur1.count());
    ```

    mul2
    lambda 只是将一个值乘以 2。transform() 算法将 mul2 应用于 vector 的每个成员。

    此转换不指定执行策略。

    输出为：

    ```text
    no policy: 4.71ms
    ```

- 可以在算法的第一个参数中指定执行策略：

    ```cpp
    std::transform(execution::seq,
        v.begin(), v.end(), v.begin(), mul2);
    ```

    seq 策略意味着算法不能并行化，这与没有执行策略一样。

    输出为：

    ```text
    execution::seq: 4.91ms
    ```

    注意，持续时间与没有策略时大致相同。因为它每次运行都会变化，所以永远不会是精确的。

- execution::par 策略允许算法并行化其工作负载：

    ```cpp
    std::transform(execution::par,
        v.begin(), v.end(), v.begin(), mul2);
    ```

    输出为：

    ```text
    execution::par: 3.22ms
    ```

    注意，使用并行执行策略时，算法运行得稍微快一些。

- execute::par_unseq 策略允许工作负载的非排序并行执行：

    ```cpp
    std::transform(execution::par_unseq,
        v.begin(), v.end(), v.begin(), mul2);
    ```

    输出为：

    ```text
    execution::par_unseq: 2.93ms
    ```

    这里，我们注意到该策略的另一个性能提升。

    execution::par_unseq 策略对算法有更严格的要求，算法不能执行需要并发或需要顺序执行的操作。

### How it works

执行策略接口没有指定如何并行算法工作负载，其设计为在不同的负载和环境下使用不同的硬件和处理器。其可以完全在库中实现，也可以依赖于编译器或硬件支持。

并行化将在运算量超过 O(n) 的算法上表现出最大的改进。例如，sort() 显示了显著的改进。下面是一个没有并行化的 sort():

```cpp
auto t0 = steady_clock::now();
std::sort(v.begin(), v.end());
dur_t dur0 = steady_clock::now() - t0;
cout << format("sort: {:.3}ms\n", dur0.count());
```

输出为：

```text
sort: 751ms
```

使用 execution::par，就可以看到显著的性能提升：

```cpp
std::sort(execution::par, v.begin(), v.end());
```

输出为：

```text
sort: 163ms
```

execution::par_unseq 的改进会更好：

```cpp
std::sort(execution::par_unseq, v.begin(), v.end());
```

输出为：

```text
sort: 152ms
```

在使用并行算法时，做大量的测试是个好主意。若算法或谓词本身不能很好地用于并行化，那么最终可能会获得最小的性能增益，或出现意想不到的副作用。

``` tcolorbox
撰写本文时，GCC 对执行策略的支持很差，LLVM/Clang 也不支持。这个示例是在运行 Windows
10 和 Visual C++预览版的 6 核 i7 上测试的。
```

## 9.6.互斥锁和锁------安全地共享数据

术语"互斥"指的是对共享资源的互斥访问。互斥锁通常用于避免由于多个执行线程，访问相同的数据而导致的数据损坏和竞争条件。互斥锁通常使用锁来限制线程的访问。

STL 在 `<mutex>` 头文件中提供了 mutex 和 lock 类。

### How to do it

这个示例中，我们将使用一个简单的 Animal 类来实验锁定和解锁互斥量：

- 首先，创建一个互斥对象：

    ```cpp
    std::mutex animal_mutex;
    ```

    互斥锁是在全局作用域中声明的，因此相关对象都可以访问它。

- 我们的 Animal 类有一个名字和一个朋友列表：

    ```cpp
    class Animal {
        using friend_t = list<Animal>;
        string_view s_name{ "unk" };
        friend_t l_friends{};
    public:
        Animal() = delete;
        Animal(const string_view n) : s_name{n} {}
        ...
    }
    ```

    添加和删除好友对互斥是一个有用的测试用例。

- 等式运算符是我们唯一需要的运算符：

    ```cpp
    bool operator==(const Animal& o) const {
        return s_name.data() == o.s_name.data();
    }
    ```

    s_name 成员是一个 string_view 对象，因此可以测试其数据存储地址是否相等。

- is_friend() 方法测试是否有其他动物在 l_friends 列表中：

    ```cpp
    bool is_friend(const Animal& o) const {
        for(const auto& a : l_friends) {
            if(a == o) return true;
        }
        return false;
    }
    ```

- find_friend() 方法返回一个可选对象，若找到 Animal，则带有指向 Animal 的迭代器：

    ```cpp
    optional<friend_t::iterator>
    find_friend(const Animal& o) noexcept {
        for(auto it{l_friends.begin()};
        it != l_friends.end(); ++it) {
            if(*it == o) return it;
        }
        return {};
    }
    ```

- print() 方法输出 s_name 和 l_friends 列表中每个 Animal 对象的名称：

    ```cpp
    void print() const noexcept {
        auto n_animals{ l_friends.size() };
        cout << format("Animal: {}, friends: ", s_name);
        if(!n_animals) cout << "none";
        else {
            for(auto n : l_friends) {
                cout << n.s_name;
                if(--n_animals) cout << ", ";
            }
        }
        cout << '\n';
    }
    ```

- add_friend() 方法将一个 Animal 对象添加到 l_friends 列表中：

    ```cpp
    bool add_friend(Animal& o) noexcept {
        cout << format("add_friend {} -> {}\n", s_name,
            o.s_name);
        if(*this == o) return false;
        std::lock_guard<std::mutex> l(animal_mutex);
        if(!is_friend(o)) l_friends.emplace_back(o);
        if(!o.is_friend(*this))
            o.l_friends.emplace_back(*this);
        return true;
    }
    ```

- delete_friend() 方法从 l_friends 列表中删除一个 Animal 对象：

    ```cpp
    bool delete_friend(Animal& o) noexcept {
        cout << format("delete_friend {} -> {}\n",
            s_name, o.s_name);
        if(*this == o) return false;
        if(auto it = find_friend(o))
            l_friends.erase(it.value());
        if(auto it = o.find_friend(*this))
            o.l_friends.erase(it.value());
        return true;
    }
    ```

- `main()` 函数中，我们创建了一些 Animal 对象：

    ```cpp
    int main() {
        auto cat1 = std::make_unique<Animal>("Felix");
        auto tiger1 = std::make_unique<Animal>("Hobbes");
        auto dog1 = std::make_unique<Animal>("Astro");
        auto rabbit1 = std::make_unique<Animal>("Bugs");
        ...
    ```

- 使用 async() 在对象上调用 add_friends()，在不同的线程中运行：

    ```cpp
    auto a1 = std::async([&]{ cat1->add_friend(*tiger1); });
    auto a2 = std::async([&]{ cat1->add_friend(*rabbit1); });
    auto a3 = std::async([&]{ rabbit1->add_friend(*dog1); });
    auto a4 = std::async([&]{ rabbit1->add_friend(*cat1); });
    a1.wait();
    a2.wait();
    a3.wait();
    a4.wait();
    ```

    可以使用 wait() 对线程进行阻塞式等待。

- 可以使用 print() 来查看动物们和他们之间的关系：

    ```cpp
    auto p1 = std::async([&]{ cat1->print(); });
    auto p2 = std::async([&]{ tiger1->print(); });
    auto p3 = std::async([&]{ dog1->print(); });
    auto p4 = std::async([&]{ rabbit1->print(); });
    p1.wait();
    p2.wait();
    p3.wait();
    p4.wait();
    ```

- 最后，使用 delete_friend() 来删除一个朋友：

    ```cpp
    auto a5 = std::async([&]{ cat1->delete_friend(*rabbit1);
    });
    a5.wait();
    auto p5 = std::async([&]{ cat1->print(); });
    auto p6 = std::async([&]{ rabbit1->print(); });
    ```

- 此时，输出是这样的：

    ```shell
    add_friend Bugs -> Felix add_friend Felix -> Hobbes
    add_friend Felix -> Bugs add_friend Bugs -> Astro Animal: Felix,
    friends: Bugs, Hobbes Animal: Hobbes, friends: Animal: Bugs,
    friends: FelixAnimal: Astro, friends: Felix , Astro Bugs
    delete_friend Felix -> Bugs Animal: Felix, friends: Hobbes Animal:
    Bugs, friends: Astro
    ```

    这个输出有点混乱。每次运行都是不同的。有时候可能没问题，但这就可能是问题。我们需要添加一些互斥锁来控制对数据的访问。

- 使用互斥的一种方法是使用它的 lock() 和 unlock() 方法，可以将其添加到 add_friend() 函数中：

    ```cpp
    bool add_friend(Animal& o) noexcept {
        cout << format("add_friend {} -> {}\n", s_name, o.s_
        name);
        if(*this == o) return false;
        animal_mutex.lock();
        if(!is_friend(o)) l_friends.emplace_back(o);
        if(!o.is_friend(*this)) o.l_friends.emplace_
        back(*this);
        animal_mutex.unlock();
        return true;
    }
    ```

    lock() 方法尝试获取互斥锁。若互斥锁已经锁定，会等待 (块执行) 互斥锁打开。

- 我们还需要添加一个锁来 delete_friend():

    ```cpp
    bool delete_friend(Animal& o) noexcept {
        cout << format("delete_friend {} -> {}\n",
            s_name, o.s_name);
        if(*this == o) return false;
        animal_mutex.lock();
        if(auto it = find_friend(o))
            l_friends.erase(it.value());
        if(auto it = o.find_friend(*this))
            o.l_friends.erase(it.value());
        animal_mutex.unlock();
        return true;
    }
    ```

- 现在，需要为 print() 添加一个锁，以便在打印时不更改数据：

    ```cpp
    void print() const noexcept {
        animal_mutex.lock();
        auto n_animals{ l_friends.size() };
        cout << format("Animal: {}, friends: ", s_name);
        if(!n_animals) cout << "none";
        else {
            for(auto n : l_friends) {
                cout << n.s_name;
                if(--n_animals) cout << ", ";
            }
        }
        cout << '\n';
        animal_mutex.unlock();
    }
    ```

    现在，输出是合理的：

    ```shell
    add_friend Bugs -> Felix add_friend Bugs -> Astro
    add_friend Felix -> Hobbes add_friend Felix -> Bugs Animal: Felix,
    friends: Bugs, Hobbes Animal: Hobbes, friends: Felix Animal: Astro,
    friends: Bugs Animal: Bugs, friends: Felix, Astro delete_friend
    Felix -> Bugs Animal: Felix, friends: Hobbes Animal: Bugs, friends:
    Astro
    ```

    由于异步操作，输出的行顺序可能不同。

- lock() 和 unlock() 方法很少直接使用。std::lock_guard 类使用适当的资源获取初始化 (RAII) 模式管理锁，该模式在销毁锁时自动释放锁。下面是带 lock_guard 的 add_friend() 方法：

    ```cpp
    bool add_friend(Animal& o) noexcept {
        cout << format("add_friend {} -> {}\n", s_name, o.s_
            name);
        if(*this == o) return false;
        std::lock_guard<std::mutex> l(animal_mutex);
        if(!is_friend(o)) l_friends.emplace_back(o);
        if(!o.is_friend(*this))
            o.l_friends.emplace_back(*this);
        return true;
    }
    ```

    lock_guard 对象创建并持有一个锁，直到它销毁。和 lock() 方法一样，lock_guard 也会阻塞至有锁可用为止。

- 让我们对 delete_friend() 和 print() 方法使用 lock_guard。

    delete_friend():

    ```cpp
    bool delete_friend(Animal& o) noexcept {
        cout << format("delete_friend {} -> {}\n",
            s_name, o.s_name);
        if(*this == o) return false;
        std::lock_guard<std::mutex> l(animal_mutex);
        if(auto it = find_friend(o))
            l_friends.erase(it.value());
        if(auto it = o.find_friend(*this))
            o.l_friends.erase(it.value());
        return true;
    }
    ```

    print():

    ```cpp
    void print() const noexcept {
        std::lock_guard<std::mutex> l(animal_mutex);
        auto n_animals{ l_friends.size() };
        cout << format("Animal: {}, friends: ", s_name);
        if(!n_animals) cout << "none";
        else {
            for(auto n : l_friends) {
                cout << n.s_name;
                if(--n_animals) cout << ", ";
            }
        }
        cout << '\n';
    }
    ```

    输出保持一致：

    ```shell
    add_friend Felix -> Hobbes add_friend Bugs -> Astro
    add_friend Felix -> Bugs add_friend Bugs -> Felix Animal: Felix,
    friends: Bugs, Hobbes Animal: Astro, friends: Bugs Animal: Hobbes,
    friends: Felix Animal: Bugs, friends: Astro, Felix delete_friend
    Felix -> Bugs Animal: Felix, friends: Hobbes Animal: Bugs, friends:
    Astro
    ```

    与前面一样，由于异步操作，输出的行顺序可能不同。

### How it works

互斥锁并不锁定数据，理解这一点很重要，它阻碍了执行。如本文所示，在对象方法中应用互斥锁时，可以使用它强制对数据进行互斥访问。

当一个线程用 lock() 或 lock_guard 锁住一个互斥量时，就说这个线程拥有这个互斥量。其他试图锁定同一个互斥锁的线程都将阻塞，直到锁的所有者将其解锁。

互斥对象在被任何线程拥有时不能被销毁。同样，当线程拥有互斥时，不能销毁。与 RAII 兼容的包装器，比如 lock_guard，将确保这种情况不会发生。

### There's more

虽然，std::mutex 提供了一个适用于许多排他性互斥锁，但 STL 确实提供了一些其他选择：

- shared_mutex 允许多个线程同时拥有一个互斥量。

- recursive_mutex 允许一个线程在一个互斥锁上叠加多个锁。

- timed_mutex
    为互斥锁提供超时。shared_mutex 和 recursive_mutex 也有定时版本可用。

## 9.7.std::atomic------共享标志和值

std::atomic 类封装了单个对象，并保证对其的操作是原子的。

写入原子对象由内存顺序策略控制，读取可能同时发生。通常用于同步不同线程之间的访问，std::atomic 从模板类型定义原子类型。类型必须普通。

若类型占用连续的内存，没有用户定义的构造函数，也没有虚成员函数，那就是普通类型。所有的基本类型都是普通类型。

虽然可以构造普通类型，但 std::atomic 最常用于简单的基本类型，如 bool、int、long、float 和 double。

### How to do it

这个示例使用一个简单的函数，循环计数器来演示共享原子对象。我们将生成一群这样的循环，作为共享原子值的线程：

- 原子对象通常放置在全局命名空间中，可以让线程访问：

    ```cpp
    std::atomic<bool> ready{};
    std::atomic<uint64_t> g_count{};
    std::atomic_flag winner{};
    ```

    ready 对象是一个 bool 类型，当所有线程都准备好开始计数时，该类型设置为 true。

    g_count 对象是一个全局计数器，由每个线程进行递增。

    winner 对象是一个特殊的 atomic_flag 类型，用于指示哪个线程先完成。

- 我们使用几个常量来控制线程数和每个线程的循环数：

    ```cpp
    constexpr int max_count{1000 * 1000};
    constexpr int max_threads{100};
    ```

    我将它设置为运行 100 个线程，并在每个线程中计算 1,000,000 次迭代。

- countem() 函数为每个线程生成，循环 max_count 次，并在每次循环迭代时增加 g_count。这是使用原子值的地方：

    ```cpp
    void countem (int id) {
        while(!ready) std::this_thread::yield();
        for(int i{}; i < max_count; ++i) ++g_count;
        if(!winner.test_and_set()) {
            std::cout << format("thread {:02} won!\n",
            id);
        }
    };
    ```

    ready 原子值用于同步线程。每个线程将调用 yield()，直到就绪值设置为 true。yield() 函数的作用是：将执行传递给其他线程。

    for 循环的每次迭代都会增加 g_count 原子值，最终值应该等于 max_count *
    max_threads。

    循环完成后，获胜者对象的 test_and_set() 方法用于报告获胜线程。test_and_set() 是 atomic_flag 类的一个方法，设置标志并返回设置之前的 bool 值。

- 我们以前使用过 make_comma() 函数，可以显示一个带有数千个分隔符的数字：

    ```cpp
    string make_commas(const uint64_t& num) {
        string s{ std::to_string(num) };
        for(long l = s.length() - 3; l > 0; l -= 3) {
            s.insert(l, ",");
        }
        return s;
    }
    ```

- `main()` 函数生成线程并显示结果：

    ```cpp
    int main() {
        vector<std::thread> swarm;
        cout << format("spawn {} threads\n", max_threads);
        for(int i{}; i < max_threads; ++i) {
            swarm.emplace_back(countem, i);
        }
        ready = true;
        for(auto& t : swarm) t.join();
        cout << format("global count: {}\n",
            make_commas(g_count));
        return 0;
    }
    ```

这里，创建一个 vector<std::thread>对象来保存线程。for 循环中，使用 emplace_back() 在 vector 中创建线程。线程生成后，设置 ready 标志，以便线程开始循环。

输出为：

```text
spawn 100 threads thread 67 won! global count: 100,000,000
```

每次运行时，都会有不同的线程获胜。

### How it works

std::atomic 类封装了一个对象来同步多个线程之间的访问。

封装的对象必须是普通类型，必须使用连续的内存，没有用户定义的构造函数，也没有虚成员函数。所有的基本类型都是普通类型。

atomic 可以使用一个简单的结构体：

```cpp
struct Trivial {
    int a;
    int b;
};
std::atomic<Trivial> triv1;
```

虽然这种用法是可能的，但并不实际。除了设置和检索复合值之外，并没有体现原子性的价值，最终需要一个互斥锁。并且，原子类最适合用于标量值。

**特化**
原子类的特化有以下几个不同的目的:

- 指针和智能指针:std::atomic<U*>特化包括对原子指针算术操作的支持，包括用于加法的 fetch_add() 和用于减法的 fetch_sub()。

- 浮点类型：当与浮点类型 float、double 和 long
    double 一起使用时，std::atomic 包括对原子浮点算术操作的支持，包括用于加法的 fetch_add() 和用于减法的 fetch_sub()。

- 整型类型：当与整型类型一起使用时，std::atomic 提供了对其他原子操作的支持，包括 fetch_add()、fetch_sub()、fetch_and()、fetch_or() 和 fetch_xor()。

**标准的别名**
STL 为所有标准标量整型提供类型别名。所以在代码中，不需要这些声明：

```cpp
std::atomic<bool> ready{};
std::atomic<uint64_t> g_count{};
```

我们可以用：

```cpp
std::atomic_bool ready{};
std::atomic_uint64_t g_count{};
```

有 46 个标准的别名，每一个代表标准的整型：

  atomic_bool       atomic_uint64_t
  ----------------- -----------------------
  atomic_char       atomic_int_least8_t
  atomic_schar      atomic_uint_least8_t
  atomic_uchar      atomic_int_least16_t
  atomic_short      atomic_uint_least16_t
  atomic_ushort     atomic_int_least32_t
  atomic_int        atomic_uint_least32_t
  atomic_uint       atomic_int_least64_t
  atomic_long       atomic_uint_least64_t
  atomic_ulong      atomic_int_fast8_t
  atomic_llong      atomic_uint_fast8_t
  atomic_ullong     atomic_int_fast16_t
  atomic_char8_t    atomic_uint_fast16_t
  atomic_char16_t   atomic_int_fast32_t
  atomic_char32_t   atomic_uint_fast32_t
  atomic_wchar_t    atomic_int_fast64_t
  atomic_int8_t     atomic_uint_fast64_t
  atomic_uint8_t    atomic_intptr_t
  atomic_int16_t    atomic_uintptr_t
  atomic_uint16_t   atomic_size_t
  atomic_int32_t    atomic_ptrdiff_t
  atomic_uint32_t   atomic_intmax_t
  atomic_int64_t    atomice_uintmax_t

**无锁版本**
大多数现代体系结构为执行原子操作提供了原子 CPU 指令，原子指令应该在硬件支持的情况下使用硬件支持。某些硬件可能不支持某些原子类型，std::atomic 可以使用互斥来确保那些特化的线程安全操作，导致线程在等待其他线程完成操作时阻塞。使用硬件支持的特化因为它们不需要互斥锁，所以称为无锁式方法。

is_lock_free() 方法检查特化是否无锁：

```cpp
cout << format("is g_count lock-free? {}\n",
    g_count.is_lock_free());
```

输出为：

```text
is g_count lock-free? true
```

这个结果对于大多数现代架构都可以正常处理。

有一些保证 std::atomic 的无锁版本可用。这些特化保证为每个目的使用最有效的硬件原子操作：

- std::atomic_signed_lock_free 有符号整型最有效的无锁特化的别名。

- std::atomic_unsigned_lock_free 是无符号整型最有效的无锁特化的别名。

- The std::atomic_flag 类提供了一个无锁原子布尔类型。

``` tcolorbox
当前 Windows 系统不支持 64 位硬件整数，即使在 64 位系统上也是如此。当在我的实验室中的一个系统上测试这段代码时，将 std::atomic<uint64_t>替换为 std::atomic_unsigned_lock_free，性能提高了 3 倍。在 64 位 Linux 和 Mac 系统上，性能没什么变化。
```

### There's more

当多个线程同时读写变量时，线程可能以不同于写入变量的顺序观察变化。memory_order 指定内存访问如何围绕原子操作排序。

std::atomic 提供了访问和更改其托管值的方法。与关联操作符不同，这些访问方法为要指定的 memory_order 提供参数。例如：

```cpp
g_count.fetch_add(1, std::memory_order_seq_cst);
```

这种情况下，memory_order_seq_cst 指定顺序一致的排序。因此，对 fetch_add() 的调用将按顺序一致地将 g_count 的值加 1。

可能的 memory_order 常量是：

- memory_order_relaxed:
    这是一个松散的操作。没有同步或排序约束，只有操作的原子性得到保证。

- memory_order_consume:
    这是一个消费型操作。在此加载之前，不能对依赖于该值的当前线程中的访问进行重排序。这只会影响编译器优化。

- memory_order_acquire:
    这是一个获取型操作。在此加载之前，访问不能重新排序。

- memory_order_release:
    这是一个存储型操作。当前线程中的访问不能在此存储之后重新排序。

- memory_order_acq_rel:
    这既是获取型，也是释放型。当前线程中的访问不能在此存储之前或之后重新排序。

- memory_order_seq_cst:
    这是顺序一致的排序，根据上下文获取或释放。加载执行获取，存储执行释放，读/写/修改同时执行。所有线程以相同的顺序观察所有修改。

    若没有指定 memory_order，则 memory_order_seq_cst 为默认值。

## 9.8.std::call_once------初始化线程

可能需要在许多线程中运行相同的代码，但只能初始化该代码一次。

一种解决方案是在运行线程之前调用初始化代码。这种方法可以工作，但有一些缺点。通过分离初始化，可以在不必要的时候调用它，也可以在必要的时候忽略它。

std::call_once 函数提供了一个更健壮的解决方案。call_once 在 `<mutex>` 头文件中声明。

### How to do it

本节中，我们使用 print 函数进行初始化，所以可以清楚地看到函数什么时候调用：

- 我们可以使用一个常量来表示要生成的线程数：

    ```cpp
    constexpr size_t max_threads{ 25 };
    ```

    还需要一个 std::once_flag 来同步 std::call_once 函数：

    ```cpp
    std::once_flag init_flag;
    ```

- 初始化函数只是打印一个字符串，让我们知道其调用了：

    ```cpp
    void do_init(size_t id) {
        cout << format("do_init ({}): ", id);
    }
    ```

- 我们的工作函数 do_print() 使用 std::call_once 来调用初始化函数，然后打印其 id:

    ```cpp
    void do_print(size_t id) {
        std::call_once(init_flag, do_init, id);
        cout << format("{} ", id);
    }
    ```

- 在 main() 中，使用列表容器来管理线程对象：

    ```cpp
    int main() {
        list<thread> spawn;
        for (size_t id{}; id < max_threads; ++id) {
            spawn.emplace_back(do_print, id);
        }
        for (auto& t : spawn) t.join();
        cout << '\n';
    }
    ```

    输出显示初始化首先发生，并且只发生一次：

    ```shell
    do_init (8): 12 0 2 1 9 6 13 10 11 5 16 3 4 17 7 15 8
    14 18 19 20 21 22 23 24
    ```

    注意，最终调用初始化函数的并不总是第一个衍生线程 (0)，但总是第一个调用。若重复运行这个命令，会看到线程 0 得到初始化，但不是每次都这样。在内核较少的系统中，初始化时更经常看到线程 0。

### How it works

std::call_once 是一个模板函数，它接受一个标志、一个可调用对象 (函数或函子) 和一个参数形参包：

```cpp
template<class Callable, class... Args>
void call_once(once_flag& flag, Callable&& f, Args&&... args);
```

可调用的 f 只调用了一次。即使 call_once 在多个线程中并发使用，f 仍然只调用了一次。

这需要一个 std::once_flag 对象进行协调，once_flag 构造函数将其状态设置为指示可调用对象尚未调用。

当 call_once 调用可调用对象时，对同一个 once_flag 的其他调用都将阻塞，直到可调用对象返回。可调用对象返回后，可以设置 once_flag，从而使后面的 call_once 直接返回，而不在调用 f。

## 9.9.std::condition_variable------解决生产者 - 消费者问题

生产者 - 消费者问题的最简单版本是，一个进程生产数据，另一个进程消费数据，使用一个缓冲区或容器保存数据。这需要生产者和消费者之间的协调来管理缓冲区并防止不必要的副作用。

### How to do it

本节中，我们考虑了一个简单的解决方案，使用 std::condition_variable 来协调这个过程：

- 方便起见，我们从一些命名空间和别名声明开始说起：

    ```cpp
    using namespace std::chrono_literals;
    namespace this_thread = std::this_thread;
    using guard_t = std::lock_guard<std::mutex>;
    using lock_t = std::unique_lock<std::mutex>;
    ```

    lock_guard 和 unique_lock 的别名，可以更容易的使用这些类型而不会出错。

- 有几个常量：

    ```cpp
    constexpr size_t num_items{ 10 };
    constexpr auto delay_time{ 200ms };
    ```

    可以把它们放在一个地方可以更安全、更容易地试验不同的值。

- 可以使用这些全局变量来协调数据存储：

    ```cpp
    std::deque<size_t> q{};
    std::mutex mtx{};
    std::condition_variable cond{};
    bool finished{};
    ```

    可以使用 deque 将数据保存在先进先出 (FIFO) 队列中。

    mutex 与 condition_variable 一起使用，以协调数据从生产者到消费者的转移。

    finished 标志表示没有更多数据。

- 生产者线程将使用这个函数：

    ```cpp
    void producer() {
        for(size_t i{}; i < num_items; ++i) {
            this_thread::sleep_for(delay_time);
            guard_t x{ mtx };
            q.push_back(i);
            cond.notify_all();
        }
        guard_t x{ mtx };
        finished = true;
        cond.notify_all();
    }
    ```

    producer() 函数循环 num_items 迭代，并在每次循环中将一个数字压入 deque。

    这里，包括使用 sleep_for() 来模拟产生每个值的延迟。

    conditional_variable 需要一个互斥锁来操作，可以使用 lock_guard(通过 guard_t 别名) 来获取锁，然后将值推到 deque 上，然后在 conditional_variable 上调用 notify_all()。这将告诉使用者线程有一个可用的新值。

    当循环完成时，可以设置 finished 标志，并通知消费者线程生产者已经完成。

- 消费者线程等待来自生产者的每个值，将其显示在控制台上，并等待 finished 标志：

    ```cpp
    void consumer() {
        while(!finished) {
            lock_t lck{ mtx };
            cond.wait(lck, [] { return !q.empty() ||
                finished; });
            while(!q.empty()) {
                cout << format("Got {} from the queue\n",
                    q.front());
                q.pop_front();
            }
        }
    }
    ```

    wait() 方法等待生产者通知，使用 lambda 作为谓词继续等待，直到 deque 不为空或设置了 finished 标志。

    当我们获取到一个值时显示它，然后将其从 deque 中弹出。

- 在 main() 中运行简单的线程对象：

    ```cpp
    int main() {
        thread t1{ producer };
        thread t2{ consumer };
        t1.join();
        t2.join();
        cout << "finished!\n";
    }
    ```

    输出为：

    ```text
    Got 0 from the queue Got 1 from the queue Got 2 from
    the queue Got 3 from the queue Got 4 from the queue Got 5 from the
    queue Got 6 from the queue Got 7 from the queue Got 8 from the queue
    Got 9 from the queue finished!
    ```

    注意，每一行之间有 200 毫秒的延迟，所以生产者和消费者之间的协调正在按照预期的方式工作。

### How it works

生产者 - 消费者问题需要在写入和读取缓冲区或容器之间进行协调。在这个例子中，容器是 deque<size_t>:

```cpp
std::deque<size_t> q{};
```

当共享变量修改时，conditional_variable 类可以阻塞一个线程或多个线程。然后，通知其他线程该值可用。

condition_variable 需要 mutex 来执行锁定操作：

```cpp
std::lock_guard x{ mtx };
q.push_back(i);
cond.notify_all();
```

std::lock_guard 会获取锁，从而可以将一个值推入到 deque 中。

condition_variable 上的 wait() 方法用于阻塞当前线程，直到收到通知：

```cpp
void wait( std::unique_lock<std::mutex>& lock );
void wait( std::unique_lock<std::mutex>& lock,
    Pred stop_waiting );
```

wait() 的谓词形式相当于：

```cpp
while (!stop_waiting()) {
    wait(lock);
}
```

谓词形式用于防止在等待特定条件时出现伪唤醒。我们的例子中，将和 lambda 一起使用：

```cpp
cond.wait(lck, []{ return !q.empty() || finished; });
```

这可以防止消费者在 deque 有数据或 finished 标志设置之前醒来。

condition_variable 类有两个通知方法：

- notify_one() 解除一个等待线程的阻塞

- notify_all() 解除所有等待线程的阻塞

示例中使用了 notify_all()。因为只有一个使用者线程，所以任何一种通知方法的工作方式都是一样的。

``` tcolorbox
注意，unique_lock 是唯一在 condition_variable 对象上支持 wait() 的锁。
```

## 9.10.实现多个生产者和消费者

生产者 - 消费者问题实际上是一组问题。若缓冲区是有界的或无界的，或者有多个生产者、多个消费者，或者两者都有，解决方案将有所不同。

来考虑一个有多个生产者、多个消费者和一个有限 (容量有限) 缓冲区的情况。

### How to do it

在这个示例中，我们将看到一个有多个生产者和消费者的情况，以及一个有界缓冲区，并使用本章中介绍的各种技术：

- 为了方便和可靠性，先从一些常量开始：

    ```cpp
    constexpr auto delay_time{ 50ms };
    constexpr auto consumer_wait{ 100ms };
    constexpr size_t queue_limit{ 5 };
    constexpr size_t num_items{ 15 };
    constexpr size_t num_producers{ 3 };
    constexpr size_t num_consumers{ 5 };
    ```

  - delay_time 是一个 duration 对象，与 sleep_for() 一起使用。

  - consumer_wait 是一个持续时间对象，与消费者条件变量一起使用。

  - queue_limit 是缓冲区限制------deque 中的最大容量值。

  - num_items 是每个生产者生产的最大产品目数。

  - num_producers 是消费者的数量。

- 需要一些对象来控制这个过程：

    ```cpp
    deque<string> qs{};
    mutex q_mutex{};
    condition_variable cv_producer{};
    condition_variable cv_consumer{};
    bool production_complete{};
    ```

  - qs 是一个字符串 deque，用于保存生成的对象。

  - q_mutex 可以对 deque 的访问进行控制。

  - queue_limt 是缓冲区限制------deque 中项目的最大容量。

  - cv_producer 是协调生产者的条件变量。

  - cv_consumer 是协调使用者的条件变量。

  - production_complete 当所有生产者线程完成时，将其设置为 true。

- producer() 线程运行这个函数：

    ```cpp
    void producer(const size_t id) {
        for(size_t i{}; i < num_items; ++i) {
            this_thread::sleep_for(delay_time * id);
            unique_lock<mutex> lock(q_mutex);
            cv_producer.wait(lock,
                [&]{ return qs.size() < queue_limit; });
            qs.push_back(format("pid {}, qs {},
                item {:02}\n", id, qs.size(), i + 1));
            cv_consumer.notify_all();
        }
    }
    ```

    传递值的 id0 用于标识生产者的连续数字。

    主 for 循环重复 num_item 次。sleep_for() 函数用于模拟生成一个项所需的一些工作。

    然后，从 q_mutex 中获得一个唯一的_lock，并在 cv_producer 上调用 wait()，使用 lambda 根据 queue_limit 常量检查 deque 的大小。若 deque 已经达到上限，生产者等待消费者线程来减小 deque 的体积。这表示生成器的有界缓冲区限制。

    当条件满足，可以将一个产品推入 deque。元素是一个格式化的字符串，包含生产者的 id、qs 的大小和来自循环控制变量的项目编号 (i +
    1)。

    最后，在 cv_consumer 条件变量上使用 notify_all() 通知消费者有新数据可用。

- consumer() 线程运行这个函数：

    ```cpp
    void consumer(const size_t id) {
        while(!production_complete) {
            unique_lock<mutex> lock(q_mutex);
            cv_consumer.wait_for(lock, consumer_wait,
                [&]{ return !qs.empty(); });
            if(!qs.empty()){
                cout << format("cid {}: {}", id,
                    qs.front());
                qs.pop_front();
            }
            cv_producer.notify_all();
        }
    }
    ```

    传递的 id 值是用于标识使用者的连续数字。

    主 while() 循环继续进行，直到对 production_complete 进行设置。

    我们从 q_mutex 中获得 unique_lock，并在 cv_consumer 上调用 wait_for()，使用一个超时和一个 lambda 来测试 deque 是否为空。这里需要超时，因为当一些消费者线程仍在运行时，生产者线程可能已经完成，可使 deque 为空。

    当有了一个非空的 deque，就可以打印 (消费) 一个产品信息，并将其从 deque 中弹出。

- 在 main() 中，使用 async() 来生成生产者线程和消费者线程。async() 符合 RAII 模式，所以我通常更喜欢使用 async。async() 返回一个 future 对象，可以保留一个 `future<void>` 对象列表用于进程管理：

    ```cpp
    int main() {
        list<future<void>> producers;
        list<future<void>> consumers;
        for(size_t i{}; i < num_producers; ++i) {
            producers.emplace_back(async(producer, i));
        }
        for(size_t i{}; i < num_consumers; ++i) {
            consumers.emplace_back(async(consumer, i));
        }
        ...
    }
    ```

    使用 for 循环来创建生产者和消费者线程。

- 最后，可以使用 future 对象的列表来确定生产者和消费者线程何时完成：

    ```cpp
    for(auto& f : producers) f.wait();
    production_complete = true;
    cout << "producers done.\n";

    for(auto& f : consumers) f.wait();
    cout << "consumers done.\n";
    ```

    循环生成器容器，调用 wait() 以允许生成器线程完成。然后，可以设置 production_complete 标志。同样，循环遍历消费者容器，调用 wait() 以允许消费者线程完成。并且，可以在这里执行最终的分析或完成过程。

- 输出有点长，就不全部展示了：

    ```shell
    cid 0: pid 0, qs 0, item 01 cid 0: pid 0, qs 1, item
    02 cid 0: pid 0, qs 2, item 03 cid 0: pid 0, qs 3, item 04 cid 0:
    pid 0, qs 4, item 05 ... cid 4: pid 2, qs 0, item 12 cid 4: pid 2,
    qs 0, item 13 cid 3: pid 2, qs 0, item 14 cid 0: pid 2, qs 0, item
    15 producers done. consumers done.
    ```

### How it works

这个配方的核心是使用两个 condition_variable 对象来异步控制生产者和消费者线程：

```cpp
condition_variable cv_producer{};
condition_variable cv_consumer{};
```

在 producer() 函数中，cv_producer 对象获得 unique_lock，等待 deque 可用，并在生成产品时通知 cv_consumer 对象：

```cpp
void producer(const size_t id) {
    for(size_t i{}; i < num_items; ++i) {
        this_thread::sleep_for(delay_time * id);
        unique_lock<mutex> lock(q_mutex);
        cv_producer.wait(lock,
            [&]{ return qs.size() < queue_limit; });
        qs.push_back(format("pid {}, qs {}, item {:02}\n",
            id, qs.size(), i + 1));
        cv_consumer.notify_all();
    }
}
```

相反，在 consumer() 函数中，cv_consumer 对象获得 unqiue_lock，等待 deque 中有产品，并在产品消费时通知 cv_producer 对象：

```cpp
void consumer(const size_t id) {
    while(!production_complete) {
        unique_lock<mutex> lock(q_mutex);
        cv_consumer.wait_for(lock, consumer_wait,
            [&]{ return !qs.empty(); });
        if(!qs.empty()) {
            cout << format("cid {}: {}", id, qs.front());
            qs.pop_front();
        }
        cv_producer.notify_all();
    }
}
```

这些锁、等待和通知，构成了多个生产者和消费者之间的动态平衡。
